{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znOoc_4jbc-_"
      },
      "source": [
        "# 필수코드\n",
        "colab 환경에서 반드시 설치되어야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLNmYGmKyCB9",
        "outputId": "bf067d70-f665-448c-e732-bcc263671968"
      },
      "outputs": [],
      "source": [
        "# 필요 시 설치(가상환경의 경우 터미널에 설치)\n",
        "!pip install transformers==4.24.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LD_vPDUyEUM",
        "outputId": "95b1642e-ef66-4d60-9742-a6dba46035eb"
      },
      "outputs": [],
      "source": [
        "# 필요 시 설치(가상환경의 경우 터미널에 설치)\n",
        "!pip install datasets==2.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg9RsYrvsjVZ",
        "outputId": "2d980e8b-5c04-4477-f344-626bc9893e63"
      },
      "outputs": [],
      "source": [
        "# 필요 시 설치\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Qix1tUfhhl"
      },
      "source": [
        "# 변수 및 함수 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUaLN4kgNv7J"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AdamW\n",
        "import pandas as pd\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhfTlbocbkKQ"
      },
      "source": [
        "## 전역 변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIC6iY-_jjen"
      },
      "outputs": [],
      "source": [
        "# 사용할 베이스 모델 설정\n",
        "base_model = 'kykim/electra-kor-base'\n",
        "classifier_hidden_size = 768\n",
        "classifier_dropout_prob = 0.1\n",
        "\n",
        "# 개체#속성 쌍 설정(label25)\n",
        "entity_property_pair = [\n",
        "    '제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도', '제품 전체#다양성',\n",
        "    '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도',\n",
        "    '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#가격', '패키지/구성품#다양성',\n",
        "    '브랜드#일반', '브랜드#가격', '브랜드#품질', '브랜드#인지도', '브랜드#디자인'\n",
        "                    ]\n",
        "\n",
        "# 개체#속성 쌍 설정(label23)\n",
        "entity_property_pair_label23 = [\n",
        "    '제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도',\n",
        "    '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도',\n",
        "    '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#가격', '패키지/구성품#다양성',\n",
        "    '브랜드#일반', '브랜드#가격', '브랜드#품질', '브랜드#인지도',\n",
        "                    ]\n",
        "\n",
        "# 문장과 개체#속성 쌍의 관계를 True, False 로 표시\n",
        "tf_id_to_name = ['True', 'False']\n",
        "tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n",
        "\n",
        "# 문장과 개체#속성 쌍의 관계로 감성을 positive, negative, neutral 로 표시\n",
        "polarity_id_to_name = ['positive', 'negative', 'neutral']\n",
        "polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n",
        "\n",
        "# 그래픽 카드 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 불러온 tokenizer 에 special token 을 추가\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuj7wDE2cYBs"
      },
      "source": [
        "## json 파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYvG2g1YjlxL"
      },
      "outputs": [],
      "source": [
        "# json 파일 읽어서 list에 저장\n",
        "def jsonload(fname, encoding=\"utf-8\"):\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        j = json.load(f)\n",
        "    return j\n",
        "\n",
        "# json 개체를 파일이름으로 저장\n",
        "def jsondump(j, fname):\n",
        "    with open(fname, \"w\", encoding=\"UTF8\") as f:\n",
        "        json.dump(j, f, ensure_ascii=False)\n",
        "\n",
        "# jsonl 파일 읽어서 list에 저장\n",
        "def jsonlload(fname, encoding=\"utf-8\"):\n",
        "    json_list = []\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        for line in f.readlines():\n",
        "            json_list.append(json.loads(line))\n",
        "    return json_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0LJb1HgqHjT"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH7TJikJgQEa"
      },
      "source": [
        "electra 모델을 기반으로 한 classification 모델 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtipLb6e080w"
      },
      "outputs": [],
      "source": [
        "# 아래 ELECTRABaseClassifier의 classifier로 사용될 class\n",
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_label):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(classifier_hidden_size, classifier_hidden_size)\n",
        "        self.dropout = nn.Dropout(classifier_dropout_prob)\n",
        "        self.output = nn.Linear(classifier_hidden_size, num_label)\n",
        "\n",
        "    def forward(self, features):\n",
        "        x = features[:, 0, :]\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# 불러올 base model 기반 classification 설정\n",
        "class ELECTRABaseClassifier(nn.Module):\n",
        "    def __init__(self, num_label, len_tokenizer):\n",
        "        super(ELECTRABaseClassifier, self).__init__()\n",
        "\n",
        "        self.num_label = num_label\n",
        "        self.xlm_roberta = AutoModel.from_pretrained(base_model)\n",
        "        self.xlm_roberta.resize_token_embeddings(len_tokenizer)\n",
        "\n",
        "        self.labels_classifier = SimpleClassifier(self.num_label)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.xlm_roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.labels_classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_label),\n",
        "                                                labels.view(-1))\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 예측 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 25개 entity_property 쌍에 대해 predict 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25개 entity_property 쌍에 대해 predict 해주는 함수\n",
        "def predict_from_korean_form(tokenizer, ce_model, pc_model, data):\n",
        "\n",
        "    ce_model.to(device)\n",
        "    ce_model.eval()\n",
        "    for sentence in data:\n",
        "        form = sentence['sentence_form']\n",
        "        sentence['annotation'] = []\n",
        "        if type(form) != str:\n",
        "            print(\"form type is arong: \", form)\n",
        "            continue\n",
        "\n",
        "        # 개체#속성 쌍을 순서대로 입력\n",
        "        for pair in entity_property_pair:\n",
        "            # 문장과 pair를 tokenizer화           \n",
        "            tokenized_data = tokenizer(form, pair, padding='max_length', max_length=256, truncation=True)\n",
        "\n",
        "            # tonkenizer 된 값으로 entity_property 모델을 통해 True, False 결과값을 출력\n",
        "            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n",
        "            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n",
        "            with torch.no_grad():\n",
        "                _, ce_logits = ce_model(input_ids, attention_mask)\n",
        "\n",
        "            ce_predictions = torch.argmax(ce_logits, dim = -1)\n",
        "\n",
        "            ce_result = tf_id_to_name[ce_predictions[0]]\n",
        "\n",
        "            # True 일 경우에만 다음 코드 진행\n",
        "            if ce_result == 'True':\n",
        "                # tonkenizer 된 값으로 polarity 모델을 통해 Positive, Negative,Neutral 결과값을 출력                \n",
        "                with torch.no_grad():\n",
        "                    _, pc_logits = pc_model(input_ids, attention_mask)\n",
        "\n",
        "                pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "                # entity_property 모델과 polarity 모델을 통해서 출력 된 결과 값을 label 입력\n",
        "                sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 23개 entity_property 쌍에 대해 predict 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 23개 entity_property 쌍에 대해 predict 해주는 함수\n",
        "def predict_from_korean_form_label23(tokenizer, ce_model, pc_model, data):\n",
        "\n",
        "    ce_model.to(device)\n",
        "    ce_model.eval()\n",
        "    for sentence in data:\n",
        "        form = sentence['sentence_form']\n",
        "        sentence['annotation'] = []\n",
        "        if type(form) != str:\n",
        "            print(\"form type is arong: \", form)\n",
        "            continue\n",
        "\n",
        "        # 개체#속성 쌍을 순서대로 입력\n",
        "        for pair in entity_property_pair_label23:\n",
        "            # 문장과 pair를 tokenizer화           \n",
        "            tokenized_data = tokenizer(form, pair, padding='max_length', max_length=256, truncation=True)\n",
        "\n",
        "            # tonkenizer 된 값으로 entity_property_pair_label23 모델을 통해 True, False 결과값을 출력\n",
        "            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n",
        "            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n",
        "            with torch.no_grad():\n",
        "                _, ce_logits = ce_model(input_ids, attention_mask)\n",
        "\n",
        "            ce_predictions = torch.argmax(ce_logits, dim = -1)\n",
        "\n",
        "            ce_result = tf_id_to_name[ce_predictions[0]]\n",
        "\n",
        "            # True 일 경우에만 다음 코드 진행\n",
        "            if ce_result == 'True':\n",
        "                # tonkenizer 된 값으로 polarity 모델을 통해 Positive, Negative,Neutral 결과값을 출력                \n",
        "                with torch.no_grad():\n",
        "                    _, pc_logits = pc_model(input_ids, attention_mask)\n",
        "\n",
        "                pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "                # entity_property 모델과 polarity 모델을 통해서 출력 된 결과 값을 label 입력\n",
        "                sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 인자로 받아온 모델들 중 entity_property가 3개인 경우 Soft_voting 을 위한 함수 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 인자로 받아온 모델들을 통해 predict 하는 문장 데이터에 label(entity_property, polarity) 해주는 함수\n",
        "#                                       모델 갯수에 따라서 ce_model 추가 또는 삭제\n",
        "def predict_from_korean_form_softvoting_3(tokenizer, ce_model1, ce_model2, ce_model3, pc_model, data):\n",
        "\n",
        "    # 모델 갯수에 따라서 ce_model 추가 또는 삭제\n",
        "    ce_model1.to(device)\n",
        "    ce_model1.eval()\n",
        "\n",
        "    ce_model2.to(device)\n",
        "    ce_model2.eval()\n",
        "\n",
        "    ce_model3.to(device)\n",
        "    ce_model3.eval()\n",
        "\n",
        "\n",
        "    for sentence in data:\n",
        "        form = sentence['sentence_form']\n",
        "        sentence['annotation'] = []\n",
        "        if type(form) != str:\n",
        "            print(\"form type is arong: \", form)\n",
        "            continue\n",
        "\n",
        "        # 개체#속성 쌍을 순서대로 입력\n",
        "        for pair in entity_property_pair:\n",
        "            # 문장과 pair를 tokenizer화 \n",
        "            tokenized_data = tokenizer(form, pair, padding='max_length', max_length=256, truncation=True)\n",
        "\n",
        "            # tonkenizer 된 값으로 entity_property 모델을 통해 True, False 결과값을 출력\n",
        "            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n",
        "            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n",
        "\n",
        "            # 문장에 대한 각 모델별 점수 예측 결과 저장\n",
        "            with torch.no_grad():\n",
        "                # 모델 갯수에 따라 추가 또는 삭제\n",
        "                _, ce_logits1 = ce_model1(input_ids, attention_mask)\n",
        "                _, ce_logits2 = ce_model2(input_ids, attention_mask)\n",
        "                _, ce_logits3 = ce_model3(input_ids, attention_mask)\n",
        "\n",
        "            # 각 모델별 예측한 결과값을 합산하여 평균 구하기\n",
        "              # 모델 갯수에 따라 추가 또는 삭제\n",
        "            logits1 = (ce_logits1[0][0]+ce_logits2[0][0]+ce_logits3[0][0])/3\n",
        "            logits2 = (ce_logits1[0][1]+ce_logits2[0][1]+ce_logits3[0][1])/3\n",
        "\n",
        "            ce_logits = torch.tensor([[logits1, logits2]]).to(device)\n",
        "\n",
        "            ce_predictions = torch.argmax(ce_logits, dim = -1)\n",
        "\n",
        "            ce_result = tf_id_to_name[ce_predictions[0]]\n",
        "\n",
        "            # True 일 경우에만 다음 코드 진행\n",
        "            if ce_result == 'True':\n",
        "\n",
        "                # tonkenizer 된 값으로 polarity 모델을 통해 Positive, Negative,Neutral 결과값을 출력                \n",
        "                with torch.no_grad():\n",
        "                    _, pc_logits = pc_model(input_ids, attention_mask)\n",
        "\n",
        "                pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "                # entity_property 모델과 polarity 모델을 통해서 출력 된 결과 값을 label 입력\n",
        "                sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 인자로 받아온 모델들 중 entity_property가 5개인 경우 Soft_voting 을 위한 함수 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_pFHKJ8GRSO"
      },
      "outputs": [],
      "source": [
        "# 인자로 받아온 모델들을 통해 predict 하는 문장 데이터에 label(entity_property, polarity) 해주는 함수\n",
        "#                                       모델 갯수에 따라서 ce_model 추가 또는 삭제\n",
        "def predict_from_korean_form_softvoting_5(tokenizer, ce_model1, ce_model2, ce_model3, ce_model4, ce_model5, pc_model, data):\n",
        "\n",
        "    # 모델 갯수에 따라서 ce_model 추가 또는 삭제\n",
        "    ce_model1.to(device)\n",
        "    ce_model1.eval()\n",
        "\n",
        "    ce_model2.to(device)\n",
        "    ce_model2.eval()\n",
        "\n",
        "    ce_model3.to(device)\n",
        "    ce_model3.eval()\n",
        "\n",
        "    ce_model4.to(device)\n",
        "    ce_model4.eval()\n",
        "\n",
        "    ce_model5.to(device)\n",
        "    ce_model5.eval()\n",
        "\n",
        "    for sentence in data:\n",
        "        form = sentence['sentence_form']\n",
        "        sentence['annotation'] = []\n",
        "        if type(form) != str:\n",
        "            print(\"form type is arong: \", form)\n",
        "            continue\n",
        "\n",
        "        # 개체#속성 쌍을 순서대로 입력\n",
        "        for pair in entity_property_pair:\n",
        "            # 문장과 pair를 tokenizer화 \n",
        "            tokenized_data = tokenizer(form, pair, padding='max_length', max_length=256, truncation=True)\n",
        "\n",
        "            # tonkenizer 된 값으로 entity_property 모델을 통해 True, False 결과값을 출력\n",
        "            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n",
        "            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n",
        "\n",
        "            # 문장에 대한 각 모델별 점수 예측 결과 저장\n",
        "            with torch.no_grad():\n",
        "                # 모델 갯수에 따라 추가 또는 삭제\n",
        "                _, ce_logits1 = ce_model1(input_ids, attention_mask)\n",
        "                _, ce_logits2 = ce_model2(input_ids, attention_mask)\n",
        "                _, ce_logits3 = ce_model3(input_ids, attention_mask)\n",
        "                _, ce_logits4 = ce_model4(input_ids, attention_mask)\n",
        "                _, ce_logits5 = ce_model5(input_ids, attention_mask)\n",
        "\n",
        "            # 각 모델별 예측한 결과값을 합산하여 평균 구하기\n",
        "              # 모델 갯수에 따라 추가 또는 삭제\n",
        "            logits1 = (ce_logits1[0][0]+ce_logits2[0][0]+ce_logits3[0][0]+ce_logits4[0][0]+ce_logits5[0][0])/5\n",
        "            logits2 = (ce_logits1[0][1]+ce_logits2[0][1]+ce_logits3[0][1]+ce_logits4[0][1]+ce_logits5[0][1])/5\n",
        "\n",
        "            ce_logits = torch.tensor([[logits1, logits2]]).to(device)\n",
        "\n",
        "            ce_predictions = torch.argmax(ce_logits, dim = -1)\n",
        "\n",
        "            ce_result = tf_id_to_name[ce_predictions[0]]\n",
        "\n",
        "            # True 일 경우에만 다음 코드 진행\n",
        "            if ce_result == 'True':\n",
        "\n",
        "                # tonkenizer 된 값으로 polarity 모델을 통해 Positive, Negative,Neutral 결과값을 출력                \n",
        "                with torch.no_grad():\n",
        "                    _, pc_logits = pc_model(input_ids, attention_mask)\n",
        "\n",
        "                pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "                # entity_property 모델과 polarity 모델을 통해서 출력 된 결과 값을 label 입력\n",
        "                sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 단일 모델에서 나온 결과물에 polarity만 바꿔주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 감성만 바꿔주는 함수(entity_property는 그대로 두며 polarity만 바꿔줌)\n",
        "def predict_from_korean_form_polarity(tokenizer, pc_model, data):\n",
        "    for sentence in data:\n",
        "        \n",
        "        form = sentence['sentence_form']\n",
        "        entity = sentence['annotation']\n",
        "        sentence['annotation'] = []\n",
        "        for i in entity:\n",
        "            tokenized_data = tokenizer(form, i[0], padding='max_length', max_length=256, truncation=True)\n",
        "\n",
        "            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n",
        "            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, pc_logits = pc_model(input_ids, attention_mask)\n",
        "\n",
        "            pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "            pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "            sentence['annotation'].append([i[0], pc_result])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 변수로 지정된 경로에 따라 predict 파일에 labeling 후 저장하는 함수\n",
        "def test_sentiment_analysis(name):\n",
        "\n",
        "    # predict 시 사용할 tokenizer와 데이터를 불러오기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonlload(test_data_path)\n",
        "    \n",
        "    # entity_property 모델 불러오기\n",
        "    model = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model.load_state_dict(torch.load(test_category_extraction_model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # polarity 모델 불러오기        \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n",
        "    pred_data = predict_from_korean_form(tokenizer, model, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    # 만들어진 predict 데이터를 json 파일로 저장\n",
        "    jsondump(pred_data, './{0:02d}.json'.format(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 변수로 지정된 경로에 따라 predict 파일에 labeling 후 저장하는 함수\n",
        "def test_sentiment_analysis_label23(name):\n",
        "\n",
        "    # predict 시 사용할 tokenizer와 데이터를 불러오기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonlload(test_data_path)\n",
        "    \n",
        "    # entity_property 모델 불러오기\n",
        "    model = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model.load_state_dict(torch.load(test_category_extraction_model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # polarity 모델 불러오기        \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n",
        "    pred_data = predict_from_korean_form_label23(tokenizer, model, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    # 만들어진 predict 데이터를 json 파일로 저장\n",
        "    jsondump(pred_data, './{0:02d}.json'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkA_4hrbqZ3j"
      },
      "source": [
        "# 지정된 모델들 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "저장할 폴더를 만들고 현재 위치를 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 저장할 폴더를 만들고 현재 위치를 옮김\n",
        "path = './tmp'\n",
        "\n",
        "os.mkdir(path)\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Soft_voting을 위한 entity_property 5개, polarity, predict 할 json 데이터 gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1rMReB5tBp2"
      },
      "outputs": [],
      "source": [
        "# 09\n",
        "!gdown 1T6zgdQOeydga6qnfXNKpPENVZpvjBhsE\n",
        "# 12\n",
        "!gdown 1Rwqkb_hdedV7Tmfa0pUncrpP0IEuxttA\n",
        "# 15\n",
        "!gdown 1d78UHgWdQF-wtUO3_GFPWsO2iTMWlYj4\n",
        "# 16\n",
        "!gdown 1BXiJBaFFR3c3_lxxXMFQMQGTGGOZQzGG\n",
        "# 22\n",
        "!gdown 1b-I9vtidwMBX-mno94oBCTdsjovIHeUk\n",
        "\n",
        "# polarity 12epoch\n",
        "!gdown 1__t7OPrvrQs0nEYswIn_hBdbK-bHAQpY\n",
        "\n",
        "# test_data\n",
        "!gdown 1M4SGcPmxUS5ocleECRxec-E1ElmNEsxW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "entity_property, polarity, predict 할 json 데이터 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43OdPtI8FQuG"
      },
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "# 5개인 경우\n",
        "entity_classification_model_path = [\n",
        "    ['./09.data_label23_epoch_5.pt',\n",
        "     './12.data+10.17_label25_epoch_5.pt',\n",
        "     './15.data+manual_label25_epoch_21.pt',\n",
        "     './16.data+similar_label25_epoch_5.pt',\n",
        "     './22.data+10.17_label25_epoch_15.pt']\n",
        "]\n",
        "\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'\n",
        "\n",
        "# 학습 후 저장된 pt 파일로 predict 할 json 데이터 설정\n",
        "test_data_path = './nikluge-sa-2022-test.jsonl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "설정된 경로를 통해 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd4wXtpOFZ5l"
      },
      "outputs": [],
      "source": [
        "# 변수로 지정된 경로에 따라 predict 파일에 labeling 후 저장하는 함수\n",
        "def test_sentiment_analysis_softvoting_5():\n",
        "\n",
        "    # predict 시 사용할 tokenizer와 데이터를 불러오기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonlload(test_data_path)\n",
        "    \n",
        "    # entity_property 모델 불러오기\n",
        "    # 모델 갯수에 따라 model1 추가 또는 삭제\n",
        "    model1 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model1.load_state_dict(torch.load(entity_classification_model_path[0][0], map_location=device))\n",
        "    model1.to(device)\n",
        "    model1.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model2추가 또는 삭제\n",
        "    model2 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model2.load_state_dict(torch.load(entity_classification_model_path[0][1], map_location=device))\n",
        "    model2.to(device)\n",
        "    model2.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model3 추가 또는 삭제\n",
        "    model3 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model3.load_state_dict(torch.load(entity_classification_model_path[0][2], map_location=device))\n",
        "    model3.to(device)\n",
        "    model3.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model4 추가 또는 삭제\n",
        "    model4 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model4.load_state_dict(torch.load(entity_classification_model_path[0][3], map_location=device))\n",
        "    model4.to(device)\n",
        "    model4.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model5 추가 또는 삭제\n",
        "    model5 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model5.load_state_dict(torch.load(entity_classification_model_path[0][4], map_location=device))\n",
        "    model5.to(device)\n",
        "    model5.eval()\n",
        "            \n",
        "    # polarity 모델 불러오기   \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "    \n",
        "    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n",
        "    # 모델 갯수에 따라 model 추가 또는 삭제\n",
        "    pred_data = predict_from_korean_form_softvoting_5(tokenizer, model1, model2, model3, model4, model5, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    # 만들어진 predict 데이터를 json 파일로 저장\n",
        "    jsondump(pred_data, './high_score_5_softvoting_62.54.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771,
          "referenced_widgets": [
            "37de72d1ce264776846c25a95ffb396c",
            "30289e7a31464b3ea94a79142c94dab8",
            "a272bbf6f72d4fbe9240c8f2ff86d4b5",
            "880afdb881994abb8f0e6b59939251ce",
            "91d314fdc8ec47869345ed35bd73d934",
            "378b977da7de42399cfd9b1a528f878f",
            "1b9c8be415e9422c9e44824181ca6304",
            "1b855be27ed049b1bfa2ac1c2f8e986a",
            "9e090d2a7f0748fbab197830e082024d",
            "10ede8a5a38b4147a99cce538b5bd073",
            "08302858a534406bacfc8cb5b859ea8d",
            "b2e590ecf5514faa94e2dc930ee52f8b",
            "17106db60b784ec68dad93e6351a4250",
            "c1c01014ae4840e1bfb4b276ff2d242b",
            "d62cdd6a62de455e8628094436bc3c65",
            "7aa3e34fc33344599f17499f2d473aa1",
            "baed98a8dd804bef872e25b95d485c23",
            "959253efbca941baa951d98f4736cd47",
            "ea9af042a63546b681209757f409af1c",
            "487e2198b0c5473d8c4d6f311cb9999b",
            "10e808b8e9694473a7fe244e56e49821",
            "95abab814a92460d8211684f77f6053d",
            "7137a1db003f4f00bec2bf0579733756",
            "10a6424247f34d56b06b90a056918ed5",
            "a10cbc078e6140ddba3eca873eadb2e6",
            "13687442f5924d69bd693b58ab6e18ee",
            "8666f2904ef64f2ca1c546242bc915ee",
            "e3d1f57516ff4cd58969c010a9998972",
            "e48e800ce4e346c299e23e76cceb557a",
            "d74b516a206e4461b7415ee0f73b46ce",
            "599a6fa0336b442faaa126801e3908af",
            "df417905e2ad42a88690d30bb124c7a3",
            "16e696f987594aa3adf9f6d1a2a7fbae",
            "4b3387f8f40b4474b22834e3cb40131d",
            "0ced9fb131604a9b9a0a211a1b2b72aa",
            "a9a620080f73404fbd0c1a81a9f52b74",
            "93bb792307c8467ea10279e58c4370b5",
            "9b0d5207329441069ba629eb51ea244a",
            "ef1006c34b82416d8ac8ef674df1d532",
            "040337196cf449948c4b30233afc8846",
            "5e5d3ee5282747d8b9cb8014f133b251",
            "7260aa6f7f694f82a22fed46a50d3e1f",
            "5eaba0aa2c164b25bc4ba5b34cc81bbf",
            "990334ee87a24feebd24fc8be8abab03"
          ]
        },
        "id": "hODIoSLjFb_s",
        "outputId": "4bb0b4d2-d3cf-4d58-aa7c-a2e3afecaad5"
      },
      "outputs": [],
      "source": [
        "# 변수로 지정된 경로에 따라 predict 파일을 생성 및 저장 함수\n",
        "test_sentiment_analysis_softvoting_5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용된 각각의 pt값을 json화 하여 이후 voting에 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './09.data_label23_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(9)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './12.data+10.17_label25_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis(12)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './16.data+similar_label25_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 entity_property 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = \"./09.data_label23_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./12.data+10.17_label25_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./16.data+similar_label25_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Soft_voting를 위한 entity_property 3개 gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 18\n",
        "!gdown 14enKPuyWp5DfTbqwK0OeVSbfKUGk_cRm\n",
        "# 20\n",
        "!gdown 190A0GbzPoU0w2oAwM_SmnSOsUdPbZyWF\n",
        "# 25\n",
        "!gdown 1QDqF8QjZnDxcC7TH5dkKWowKtKytGi5C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "entity_property 경로 재설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "# 5개인 경우 예시\n",
        "entity_classification_model_path = [\n",
        "    ['./15.data+manual_label25_epoch_21.pt',\n",
        "     './18.data_label23_epoch_5.pt',\n",
        "     './20.data+108+10.17+10.24_label25_epoch_8.pt',\n",
        "     './22.data+10.17_label25_epoch_15.pt',\n",
        "     './25.data+108+10.17+10.24_label23_epoch_10.pt']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "설정된 경로를 통해 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 변수로 지정된 경로에 따라 predict 파일에 labeling 후 저장하는 함수\n",
        "def test_sentiment_analysis_softvoting_5():\n",
        "\n",
        "    # predict 시 사용할 tokenizer와 데이터를 불러오기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonlload(test_data_path)\n",
        "    \n",
        "    # entity_property 모델 불러오기\n",
        "    # 모델 갯수에 따라 model1 추가 또는 삭제\n",
        "    model1 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model1.load_state_dict(torch.load(entity_classification_model_path[0][0], map_location=device))\n",
        "    model1.to(device)\n",
        "    model1.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model2추가 또는 삭제\n",
        "    model2 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model2.load_state_dict(torch.load(entity_classification_model_path[0][1], map_location=device))\n",
        "    model2.to(device)\n",
        "    model2.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model3 추가 또는 삭제\n",
        "    model3 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model3.load_state_dict(torch.load(entity_classification_model_path[0][2], map_location=device))\n",
        "    model3.to(device)\n",
        "    model3.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model4 추가 또는 삭제\n",
        "    model4 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model4.load_state_dict(torch.load(entity_classification_model_path[0][3], map_location=device))\n",
        "    model4.to(device)\n",
        "    model4.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model5 추가 또는 삭제\n",
        "    model5 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model5.load_state_dict(torch.load(entity_classification_model_path[0][4], map_location=device))\n",
        "    model5.to(device)\n",
        "    model5.eval()\n",
        "            \n",
        "    # polarity 모델 불러오기   \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "    \n",
        "    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n",
        "    # 모델 갯수에 따라 model 추가 또는 삭제\n",
        "    pred_data = predict_from_korean_form_softvoting_5(tokenizer, model1, model2, model3, model4, model5, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    # 만들어진 predict 데이터를 json 파일로 저장\n",
        "    jsondump(pred_data, './pt_5_softvoting_62.15.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sentiment_analysis_softvoting_5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 사용된 각각의 pt값을 json화 하여 이후 voting에 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "단일 모델 중 필요한 polarity gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 18 polarity\n",
        "!gdown 1hDTlfC17xXGcP-Fhq7jcAkJ5z_ly2LiB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './15.data+manual_label25_epoch_21.pt'\n",
        "\n",
        "test_sentiment_analysis(15)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './18.data_label23_epoch_5.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './18.data_polarity_label23_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis(18)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './20.data+108+10.17+10.24_label25_epoch_8.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'\n",
        "\n",
        "test_sentiment_analysis(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 entity_property 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = \"./15.data+manual_label25_epoch_21.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./18.data_label23_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = './18.data_polarity_label23_epoch_5.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./20.data+108+10.17+10.24_label25_epoch_8.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./25.data+108+10.17+10.24_label23_epoch_10.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Soft_voting를 위한 entity_property 2개 gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 21\n",
        "!gdown 184zfO0Bp9cNVtjsfUk68ts-nrqItrz6R\n",
        "# 23\n",
        "!gdown 1fvmtIYEjuoAWcds7Wf6wwvVeEIuGdduj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "entity_property 경로 재설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "# 5개인 경우 예시\n",
        "entity_classification_model_path = [\n",
        "    ['./21.data_all_label25_epoch_30.pt.',\n",
        "     './22.data+10.17_label25_epoch_15.pt',\n",
        "     './23.data+similar_label25_epoch_10.pt']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "재설정된 경로를 통해 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_sentiment_analysis_softvoting_3():\n",
        "\n",
        "    # predict 시 사용할 tokenizer와 데이터를 불러오기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonlload(test_data_path)\n",
        "    \n",
        "    # entity_property 모델 불러오기\n",
        "    # 모델 갯수에 따라 model1 추가 또는 삭제\n",
        "    model1 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model1.load_state_dict(torch.load(entity_classification_model_path[0][0], map_location=device))\n",
        "    model1.to(device)\n",
        "    model1.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model2추가 또는 삭제\n",
        "    model2 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model2.load_state_dict(torch.load(entity_classification_model_path[0][1], map_location=device))\n",
        "    model2.to(device)\n",
        "    model2.eval()\n",
        "\n",
        "    # 모델 갯수에 따라 model3 추가 또는 삭제\n",
        "    model3 = ELECTRABaseClassifier(len(tf_id_to_name), len(tokenizer))\n",
        "    model3.load_state_dict(torch.load(entity_classification_model_path[0][2], map_location=device))\n",
        "    model3.to(device)\n",
        "    model3.eval()\n",
        "            \n",
        "    # polarity 모델 불러오기   \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "    \n",
        "    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n",
        "    # 모델 갯수에 따라 model 추가 또는 삭제\n",
        "    pred_data = predict_from_korean_form_softvoting_3(tokenizer, model1, model2, model3, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    # 만들어진 predict 데이터를 json 파일로 저장\n",
        "    jsondump(pred_data, './pt_3_softvoting_61.15.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sentiment_analysis_softvoting_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 사용된 각각의 pt값을 json화 하여 이후 voting에 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "단일 모델 중 필요한 polarity gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gdown 15uW-s-xl38qmXNiVy0LJyufYY8Hdyz02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './21.data_all_label25_epoch_30.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './21.data_all_polarity_label25_epoch_30.pt'\n",
        "\n",
        "test_sentiment_analysis(21)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './22.data+10.17_label25_epoch_15.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'\n",
        "\n",
        "test_sentiment_analysis(22)\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './23.data+similar_label25_epoch_10.pt'\n",
        "\n",
        "test_sentiment_analysis(23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 entity_property 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = \"./21.data_all_label25_epoch_30.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./21.data_all_polarity_label25_epoch_30.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "\n",
        "remove_path = \"./22.data+10.17_label25_epoch_15.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = \"./23.data+similar_label25_epoch_10.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 단일 모델을 통한 pred_data만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1\n",
        "!gdown 17r1cYHKhYmYZKQS3onQeHq0idTwQDdaF\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './01.data+108_label23_epoch_1.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(1)\n",
        "\n",
        "remove_path = \"./01.data+108_label23_epoch_1.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2\n",
        "!gdown 15XVi_9M2tCzpSq-NXHi63Ci7E-Vzf0Ij\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './02.data+108+10.17+1024_label23_epoch_2.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(2)\n",
        "\n",
        "remove_path = \"./02.data+108+10.17+1024_label23_epoch_2.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3\n",
        "!gdown 10PuAaK3-tDr4oqydSh6IaNolCSmOd8PA\n",
        "# polarity\n",
        "!gdown 1EGGOZy-aDd1fLGy68x4H8lbagq47gTnW\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './03.data_label25_epoch_5.pt'\n",
        "\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './03.data_polarity_label25_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis(3)\n",
        "\n",
        "remove_path = \"./03.data_label25_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = './03.data_polarity_label25_epoch_5.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4\n",
        "!gdown 1JgBKU8qkDod3p0geNe4DAH0-z0_Hnf8q\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './04.data+108+10.17+10.24_label23_epoch_5.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(4)\n",
        "\n",
        "remove_path = \"./04.data+108+10.17+10.24_label23_epoch_5.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5\n",
        "!gdown 1k8K_0ltOy3QZbKaexhOaAQ1QvgspVUlk\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './05.data+108_label23_epoch_11.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(5)\n",
        "\n",
        "remove_path = \"./05.data+108_label23_epoch_11.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6\n",
        "!gdown 1svN_-bhM-lzsse-i_og5SgJK9hTOAPNY\n",
        "# polarity\n",
        "!gdown 1GFdbS3SNuuj7bk0U7WhZe_Sf5SqsMsjP\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './06.data+10.17_label25_epoch_14.pt'\n",
        "\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './06.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "test_sentiment_analysis(6)\n",
        "\n",
        "remove_path = './06.data+10.17_label25_epoch_14.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = './06.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7\n",
        "!gdown 12iWcsaf4yEj5cXBSB-zcfJIAQ4UY56nN\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './07.data+108_label23_epoch_7.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(7)\n",
        "\n",
        "remove_path = \"./07.data+108_label23_epoch_7.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8\n",
        "!gdown 1--cvb_ouiHNxFPT9qD6AtJAMfLgQgbNx\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './08.data+108_label23_epoch_3.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(8)\n",
        "\n",
        "remove_path = \"./08.data+108_label23_epoch_3.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10\n",
        "!gdown 14OFWVTqiGIlz5rLrotxcIsjWvcc4W_Sm\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './10.final_data_label25_epoch_16.pt'\n",
        "\n",
        "test_sentiment_analysis(10)\n",
        "\n",
        "remove_path = \"./10.final_data_label25_epoch_16.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11\n",
        "! gdown 1sKNvIFG2yev6S03aG4PDnkoFDDkA8LXI\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './11.data+108+10.17+10.24_label25_epoch_12.pt'\n",
        "\n",
        "test_sentiment_analysis(11)\n",
        "\n",
        "remove_path = \"./11.data+108+10.17+10.24_label25_epoch_12.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13\n",
        "! gdown 17VzlAINzT_6stuM_kbOqp72UQYzARGl1\n",
        "# polarity\n",
        "! gdown 1sH3RqfohrY81BByvFyKKcTAIcQMbVUyR\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './13.data_label25_epoch_30.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './13.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "test_sentiment_analysis(13)\n",
        "\n",
        "remove_path = \"./13.data_label25_epoch_30.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "    \n",
        "remove_path = './13.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14\n",
        "! gdown 1RE67eYxq43u_GzL7Foc-1jDqKaOSghe4\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './14.data+108+10.17+10.24_label23_epoch_15.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(14)\n",
        "\n",
        "remove_path = \"./14.data+108+10.17+10.24_label23_epoch_15.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 17\n",
        "! gdown 1tpO4ZNETNhrOjjE1NiZo8ISBd1iE39uK\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './17.data+manual_label25_epoch_21.pt'\n",
        "\n",
        "test_sentiment_analysis(17)\n",
        "\n",
        "remove_path = \"./17.data+manual_label25_epoch_21.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 19\n",
        "! gdown 1u2G88GAsxd26aqU-8FUCqj6e90Dkts5F\n",
        "# polarity\n",
        "! gdown 1llHgAIs2YyJqrhpkL5hrlVD-QhSO-LA9\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './19.data+10.17_label23_epoch_10.pt'\n",
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './19.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "test_sentiment_analysis_label23(19)\n",
        "\n",
        "remove_path = \"./19.data+10.17_label23_epoch_10.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = './19.data_polarity_label25_epoch_30.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 불러올 polarity pt 파일 경로 설정\n",
        "polarity_classification_model_path = './data_polarity_epoch_12.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 24\n",
        "! gdown 15eKRn0P8gFYH8XMXUvvrg-Q4zbqW9bWf\n",
        "\n",
        "# 불러올 entity_property pt 파일 경로 설정\n",
        "test_category_extraction_model_path = './24.data+10.17_label25_epoch_21.pt'\n",
        "\n",
        "test_sentiment_analysis(24)\n",
        "\n",
        "remove_path = \"./24.data+10.17_label25_epoch_21.pt\"\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 만들어진 json 파일을 통해 hard voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "만들어진 json 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_1 = './01.json'\n",
        "path_2 = './02.json'\n",
        "path_3 = './03.json'\n",
        "path_4 = './04.json'\n",
        "path_5 = './05.json'\n",
        "path_6 = './06.json'\n",
        "path_7 = './07.json'\n",
        "path_8 = './08.json'\n",
        "path_9 = './09.json'\n",
        "path_10 = './10.json'\n",
        "path_11 = './11.json'\n",
        "path_12 = './12.json'\n",
        "path_13 = './13.json'\n",
        "path_14 = './14.json'\n",
        "path_15 = './15.json'\n",
        "path_16 = './16.json'\n",
        "path_17 = './17.json'\n",
        "path_18 = './18.json'\n",
        "path_19 = './19.json'\n",
        "path_20 = './20.json'\n",
        "path_21 = './21.json'\n",
        "path_22 = './22.json'\n",
        "path_23 = './23.json'\n",
        "path_24 = './24.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 특정 json 3개로 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( path_15,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( path_8,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_9,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open(path_15,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./62.97_1109.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 특정 json 12개로 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open(path_9, 'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open(path_16, 'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open(path_15, 'r', encoding='utf-8')]\n",
        "data_3 = [json.loads(line) for line in open(path_8, 'r', encoding='utf-8')]\n",
        "data_4 = [json.loads(line) for line in open(path_7, 'r', encoding='utf-8')]\n",
        "data_5 = [json.loads(line) for line in open(path_5, 'r', encoding='utf-8')]\n",
        "data_6 = [json.loads(line) for line in open(path_6, 'r', encoding='utf-8')]\n",
        "data_7 = [json.loads(line) for line in open(path_4, 'r', encoding='utf-8')]\n",
        "data_8 = [json.loads(line) for line in open(path_3, 'r', encoding='utf-8')]\n",
        "data_9 = [json.loads(line) for line in open(path_19, 'r', encoding='utf-8')]\n",
        "data_10 = [json.loads(line) for line in open(path_2, 'r', encoding='utf-8')]\n",
        "data_11 = [json.loads(line) for line in open(path_1, 'r', encoding='utf-8')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#결과값 저장할 제이슨 형식\n",
        "data_final = [json.loads(line) for line in open(path_9, 'r', encoding='utf-8')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#하드부팅 가중치 설정\n",
        "\n",
        "wv_0 = 62.1\n",
        "wv_1 = 61.82\n",
        "wv_2 = 61.8\n",
        "wv_3 = 61.67\n",
        "wv_4 = 61.03\n",
        "wv_5 = 60.56\n",
        "wv_6 = 60.79\n",
        "wv_7 = 60.11\n",
        "wv_8 = 59.7\n",
        "wv_9 = 59.44\n",
        "wv_10 = 53.35\n",
        "wv_11 = 52.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_data = [data_0, data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10, data_11]\n",
        "list_wv = [wv_0, wv_1, wv_2, wv_3, wv_4, wv_5, wv_6,wv_7, wv_8, wv_9, wv_10, wv_11]\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "   \n",
        "   #공백정답미포함\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#제출데이터 형식에 맞추기\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./62.87_1117.json\", \"w\",encoding='utf-8') as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hard_voting로 만들어진 두개의 json을 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_base = [json.loads(line) for line in open(\"./62.97_1109.json\", 'r', encoding='utf-8')]\n",
        "data_plus = [json.loads(line) for line in open(\"./62.87_1117.json\", 'r', encoding='utf-8')]\n",
        "\n",
        "for k in range(len(data_base[0])):\n",
        "    if len(data_base[0][k]['annotation']) == 0:\n",
        "        data_base[0][k]['annotation'] = data_plus[0][k]['annotation']\n",
        "\n",
        "with open(\"./63.16_2191.json\", \"w\", encoding='utf-8') as f:\n",
        "    json.dump(data_base[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## soft_votind의 json 1개, hard_voting의 json 1개, 단일 모델 json 1개, 총 3개 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './high_score_5_softvoting_62.54.json','r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.16_2191.json','r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_10,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open('./high_score_5_softvoting_62.54.json','r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.57_3579.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 단일 모델로 만든 특정 json 3개 hard_voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### path_11,12,19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( path_11 ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_19 ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( path_11 ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./62.98_c3a.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### path_12,13,14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( path_13 ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_14 ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./62.97_3ed.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## soft_voting의 json 1개, hard_voting의 특정 json 2개, 단일 모델의 특정 json 2개, 총 5개 hard_voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### high_score_5_softvoting_62.54, 63.16_2191, 62.98_c3a, path_24,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './high_score_5_softvoting_62.54.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.16_2191.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './62.98_c3a.json' ,'r', encoding='utf-8')]\n",
        "data_3 = [json.loads(line) for line in open(path_24, 'r', encoding='utf-8')]\n",
        "data_4 = [json.loads(line) for line in open(path_9, 'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './62.97_3ed.json', 'r', encoding='utf-8')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_0 = 62.1\n",
        "wv_1 = 61.67\n",
        "wv_2 = 52.25\n",
        "wv_3 = 53.35\n",
        "wv_4 = 59.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_0, data_1, data_2, data_3, data_4]\n",
        "list_wv = [wv_0, wv_1, wv_2, wv_3, wv_4]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "\n",
        "\n",
        "with open(\"./63.60_21312.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### high_score_5_softvoting_62.54, 63.16_2191, 62.98_c3a, path_24,12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './high_score_5_softvoting_62.54.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.16_2191.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './62.98_c3a.json' ,'r', encoding='utf-8')]\n",
        "data_3 = [json.loads(line) for line in open(path_24, 'r', encoding='utf-8')]\n",
        "data_4 = [json.loads(line) for line in open(path_12, 'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './62.97_3ed.json', 'r', encoding='utf-8')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_0 = 62.1\n",
        "wv_1 = 61.67\n",
        "wv_2 = 52.25\n",
        "wv_3 = 53.35\n",
        "wv_4 = 59.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_0, data_1, data_2, data_3, data_4]\n",
        "list_wv = [wv_0, wv_1, wv_2, wv_3, wv_4]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "\n",
        "\n",
        "with open(\"./63.41_21313.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### high_score_5_softvoting_62.54, 63.16_2191, 62.98_3ed, path_24,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './high_score_5_softvoting_62.54.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.16_2191.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './62.97_3ed.json' ,'r', encoding='utf-8')]\n",
        "data_3 = [json.loads(line) for line in open(path_24, 'r', encoding='utf-8')]\n",
        "data_4 = [json.loads(line) for line in open(path_9, 'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './62.98_c3a.json' ,'r', encoding='utf-8')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_0 = 62.1\n",
        "wv_1 = 61.67\n",
        "wv_2 = 52.25\n",
        "wv_3 = 53.35\n",
        "wv_4 = 59.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_0, data_1, data_2, data_3, data_4]\n",
        "list_wv = [wv_0, wv_1, wv_2, wv_3, wv_4]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "   \n",
        "   #공백정답미포함\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "\n",
        "\n",
        "with open(\"./63.49_21212.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### pt_5_softvoting_62.15, 63.16_2191, 62.98_c3a, path_24,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './pt_5_softvoting_62.15.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.16_2191.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './62.98_c3a.json' ,'r', encoding='utf-8')]\n",
        "data_3 = [json.loads(line) for line in open(path_24, 'r', encoding='utf-8')]\n",
        "data_4 = [json.loads(line) for line in open(path_9, 'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './62.97_3ed.json', 'r', encoding='utf-8')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_0 = 62.1\n",
        "wv_1 = 61.67\n",
        "wv_2 = 52.25\n",
        "wv_3 = 53.35\n",
        "wv_4 = 59.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_0, data_1, data_2, data_3, data_4]\n",
        "list_wv = [wv_0, wv_1, wv_2, wv_3, wv_4]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "   \n",
        "   #공백정답미포함\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "\n",
        "\n",
        "with open(\"./63.46_11312.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 단일 모델로 만든 특정 json 3개 hard_voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### path_12,13,17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( path_13 ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_17 ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./62.9_3e4.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### path_17,12,16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( path_17 ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( path_12 ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( path_16 ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( path_17 ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./62.98_435.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hard_voting 결과물 중 특정 json 7개 선정 및 선정된 7개의 json 중에서 5개 hard_voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7개의 json 번호 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#하드부팅 데이터\n",
        "data_1 = [json.loads(line) for line in open(\"./63.16_2191.json\", 'r')]\n",
        "data_2 = [json.loads(line) for line in open('./62.87_1117.json', 'r')]\n",
        "data_3 = [json.loads(line) for line in open(\"./62.9_3e4.json\", 'r')]\n",
        "data_4 = [json.loads(line) for line in open('./62.98_c3a.json', 'r')]\n",
        "data_5 = [json.loads(line) for line in open('./62.97_3ed.json', 'r')]\n",
        "data_6 = [json.loads(line) for line in open('./62.97_1109.json', 'r')]\n",
        "data_7 = [json.loads(line) for line in open('./62.98_435.json', 'r')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data_1,2,4,5,7 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_1 = 63.16\n",
        "wv_2 = 62.87\n",
        "wv_3 = 62.9\n",
        "wv_4 = 62.98\n",
        "wv_5 = 62.97\n",
        "wv_6 = 62.97\n",
        "wv_7 = 62.98"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#결과값 저장할 제이슨 형식\n",
        "data_final = [json.loads(line) for line in open('./62.98_435.json', 'r')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_1, data_2, data_4, data_5, data_7]\n",
        "list_wv = [wv_1,wv_2, wv_4, wv_5, wv_7]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_1[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "  \n",
        "\n",
        "\n",
        "with open(\"./63.47_12457.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data_1,2,3,4,7 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_1, data_2, data_3, data_4, data_7]\n",
        "list_wv = [wv_1,wv_2, wv_3, wv_4, wv_7]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_1[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "  \n",
        "\n",
        "\n",
        "with open(\"./63.44_12347.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data_2,4,5,6,7 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#정답에 빈값이 있는경우, 중간에 주석처리로 변경가능\n",
        "#최빈값 찾기\n",
        "\n",
        "list_data = [data_2, data_4, data_5, data_6, data_7]\n",
        "list_wv = [wv_2,wv_4, wv_5, wv_6, wv_7]\n",
        "list_aaa = []\n",
        "\n",
        "\n",
        "for i in range(len(data_1[0])):\n",
        "  board = defaultdict(int)\n",
        "  \n",
        "  for j in range(len(list_data)):\n",
        "\n",
        "    annotation = ''\n",
        "    for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "      if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "      else:\n",
        "        annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "    if annotation != '':\n",
        "      board[annotation] += list_wv[j]\n",
        "\n",
        "\n",
        "  tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "  list_aaa.append(tmp)\n",
        "\n",
        "for i in range(len(list_aaa)):\n",
        "  data_a = []\n",
        "  if len(list_aaa[i]) != 0:\n",
        "    for j in range(len(list_aaa[i][0].split(','))):\n",
        "      if list_aaa[i][0] != '':\n",
        "        data_b = []\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[0])\n",
        "        data_b.append(list_aaa[i][0].split(',')[j].split('$')[1])\n",
        "        data_a.append(data_b)\n",
        "      \n",
        "\n",
        "    data_final[0][i]['annotation'] = data_a\n",
        "  \n",
        "\n",
        "\n",
        "with open(\"./63.54_24567.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hard_voting 결과물 중 특정 json 3개 선정 및 선정된 3개로 hard_voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.60_21312, 63.47_12457. 63.41_21313"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.60_21312.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.47_12457.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.41_21313.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.60_21312.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.62_146.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.54_24567, 63.44_12347, 63,41_21313"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.54_24567.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.44_12347.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.41_21313.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.54_24567.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.60_356.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.46_11312. 63.60_21312. 63.49_21212"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.46_11312.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.60_21312.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.49_21212.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.46_11312.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.65_shd_hs_312.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.57_3579, 63.62_146, 63.60_356"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.57_3579.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.62_146.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.60_356.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.57_3579.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.85_645.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.60_356, 63.65_shd_hs_312, 63.57_3579"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.60_356.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.65_shd_hs_312.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.57_3579.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.60_356.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.87_536.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.60_21312, 63.54_24567, 63.41_21313"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.60_21312.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.54_24567.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.41_21313.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.60_21312.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.68_136.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.68_136, 63.65_shd_hs_312, 63.57_3579"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.68_136.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.65_shd_hs_312.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.57_3579.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.68_136.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.80_136.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 63.85_645, 63.87_536, 63.80_136"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.85_645.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.87_536.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.80_136.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.85_645.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.89_213.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hard_voting 특정 json 1개, 단일 모델 특정 json 1개, soft_voting 특정 json 1개 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.89_213.json' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './08.json' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './pt_3_softvoting_61.15.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.89_213.json' ,'r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./63.90_132.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# polarity_change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "change 할 polarity gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gdown 1596e_lhhEvTMbkscHc2ygypqA3hNbIVW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "polarity_change 할 json 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 바꿔줄 pred_data파일 경로 설정\n",
        "test_data_path = './63.90_132.json'\n",
        "\n",
        "# 사용할 베이스 모델 설정\n",
        "base_model = 'kykim/electra-kor-base'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "polarity_change 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_sentiment_analysis_save():\n",
        "    # polarity pt 파일 경로 설정\n",
        "    test_polarity_classification_model_path = './data_polarity_epoch_10.pt'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonload(test_data_path)\n",
        "            \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(test_polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    pred_data = predict_from_korean_form_polarity(tokenizer, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    jsondump(pred_data, './63.90_10epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sentiment_analysis_save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 polarity 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = './data_polarity_epoch_10.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "polarity gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gdown 1s3XP91Vp8zqJs5jejz-5AEQNVFOT1Mev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "변경된 polarity로 polarity_change 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_sentiment_analysis_save():\n",
        "    # polarity pt 파일 경로 설정\n",
        "    test_polarity_classification_model_path = './data_polarity_negative_plus_epoch_3.pt'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonload(test_data_path)\n",
        "            \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(test_polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    pred_data = predict_from_korean_form_polarity(tokenizer, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    jsondump(pred_data, './63.90_negative_plus_3epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sentiment_analysis_save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 polarity 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = './data_polarity_negative_plus_epoch_3.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용할 base_model 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = 'beomi/KcELECTRA-base'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "polarity gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gdown 19TpczS4kFATxPGuqqiFt0E7zE-bJz86H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "변경된 polarity로 polarity_change 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_sentiment_analysis_save():\n",
        "    # polarity pt 파일 경로 설정\n",
        "    test_polarity_classification_model_path = './data_polarity_kcelectra_epoch_6.pt'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    test_data = jsonload(test_data_path)\n",
        "            \n",
        "    polarity_model = ELECTRABaseClassifier(len(polarity_id_to_name), len(tokenizer))\n",
        "    polarity_model.load_state_dict(torch.load(test_polarity_classification_model_path, map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    pred_data = predict_from_korean_form_polarity(tokenizer, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    jsondump(pred_data, './63.90_kcelectra_6epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sentiment_analysis_save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용 완료한 polarity 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_path = './data_polarity_kcelectra_epoch_6.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)\n",
        "\n",
        "remove_path = './data_polarity_epoch_12.pt'\n",
        "\n",
        "if os.path.exists(remove_path):\n",
        "    os.remove(remove_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# polarity_change 한 결과물들 총 3개로 hard_voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_0 = [json.loads(line) for line in open( './63.90_kcelectra_6epoch' ,'r', encoding='utf-8')]\n",
        "data_1 = [json.loads(line) for line in open( './63.90_10epoch' ,'r', encoding='utf-8')]\n",
        "data_2 = [json.loads(line) for line in open( './63.90_negative_plus_3epoch' ,'r', encoding='utf-8')]\n",
        "\n",
        "data_final = [json.loads(line) for line in open( './63.90_kcelectra_6epoch','r', encoding='utf-8')]\n",
        "\n",
        "wv_0 = 1.3\n",
        "wv_1 = 1.2\n",
        "wv_2 = 1.1\n",
        "\n",
        "\n",
        "list_data = [data_0, data_1, data_2]\n",
        "list_wv = [wv_0, wv_1, wv_2]\n",
        "\n",
        "list_aaa = []\n",
        "\n",
        "for i in range(len(data_0[0])):\n",
        "    board = defaultdict(int)\n",
        "\n",
        "    for j in range(len(list_data)):\n",
        "        annotation = ''\n",
        "        for q in range(len(list_data[j][0][i]['annotation'])):\n",
        "            if q == len(list_data[j][0][i]['annotation'])-1:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1]\n",
        "            else:\n",
        "                annotation = annotation + list_data[j][0][i]['annotation'][q][0] +'$'+ list_data[j][0][i]['annotation'][q][1] +','   \n",
        "        if annotation != '':\n",
        "            board[annotation] += list_wv[j]\n",
        "\n",
        "    tmp = [k for k,v in board.items() if max(board.values()) == v]\n",
        "    list_aaa.append(tmp)\n",
        "\n",
        "for l in range(len(list_aaa)):\n",
        "    data_a = []\n",
        "    if len(list_aaa[l]) != 0:\n",
        "        for jj in range(len(list_aaa[l][0].split(','))):\n",
        "            if list_aaa[l][0] != '':\n",
        "                data_b = []\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[0])\n",
        "                data_b.append(list_aaa[l][0].split(',')[jj].split('$')[1])\n",
        "                data_a.append(data_b)\n",
        "        \n",
        "\n",
        "        data_final[0][l]['annotation'] = data_a\n",
        "\n",
        "with open(\"./64.25.json\", \"w\") as f:\n",
        "    json.dump(data_final[0], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 완성된 json 파일을 jsonl화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_data = jsonload('./64.25.json')\n",
        "\n",
        "with open(\"final_potential.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
        "\tfor i in row_data: file.write(json.dumps(i) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('test')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "8d9cd5405d0ea994988d9a1870a24bed550406ecac442e5d6c65a056768d87d5"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "040337196cf449948c4b30233afc8846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08302858a534406bacfc8cb5b859ea8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ced9fb131604a9b9a0a211a1b2b72aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1006c34b82416d8ac8ef674df1d532",
            "placeholder": "​",
            "style": "IPY_MODEL_040337196cf449948c4b30233afc8846",
            "value": "Downloading: 100%"
          }
        },
        "10a6424247f34d56b06b90a056918ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d1f57516ff4cd58969c010a9998972",
            "placeholder": "​",
            "style": "IPY_MODEL_e48e800ce4e346c299e23e76cceb557a",
            "value": "Downloading: 100%"
          }
        },
        "10e808b8e9694473a7fe244e56e49821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ede8a5a38b4147a99cce538b5bd073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13687442f5924d69bd693b58ab6e18ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df417905e2ad42a88690d30bb124c7a3",
            "placeholder": "​",
            "style": "IPY_MODEL_16e696f987594aa3adf9f6d1a2a7fbae",
            "value": " 344k/344k [00:00&lt;00:00, 558kB/s]"
          }
        },
        "16e696f987594aa3adf9f6d1a2a7fbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17106db60b784ec68dad93e6351a4250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baed98a8dd804bef872e25b95d485c23",
            "placeholder": "​",
            "style": "IPY_MODEL_959253efbca941baa951d98f4736cd47",
            "value": "Downloading: 100%"
          }
        },
        "1b855be27ed049b1bfa2ac1c2f8e986a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9c8be415e9422c9e44824181ca6304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30289e7a31464b3ea94a79142c94dab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378b977da7de42399cfd9b1a528f878f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b9c8be415e9422c9e44824181ca6304",
            "value": "Downloading: 100%"
          }
        },
        "378b977da7de42399cfd9b1a528f878f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37de72d1ce264776846c25a95ffb396c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30289e7a31464b3ea94a79142c94dab8",
              "IPY_MODEL_a272bbf6f72d4fbe9240c8f2ff86d4b5",
              "IPY_MODEL_880afdb881994abb8f0e6b59939251ce"
            ],
            "layout": "IPY_MODEL_91d314fdc8ec47869345ed35bd73d934"
          }
        },
        "487e2198b0c5473d8c4d6f311cb9999b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b3387f8f40b4474b22834e3cb40131d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ced9fb131604a9b9a0a211a1b2b72aa",
              "IPY_MODEL_a9a620080f73404fbd0c1a81a9f52b74",
              "IPY_MODEL_93bb792307c8467ea10279e58c4370b5"
            ],
            "layout": "IPY_MODEL_9b0d5207329441069ba629eb51ea244a"
          }
        },
        "599a6fa0336b442faaa126801e3908af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e5d3ee5282747d8b9cb8014f133b251": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eaba0aa2c164b25bc4ba5b34cc81bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7137a1db003f4f00bec2bf0579733756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10a6424247f34d56b06b90a056918ed5",
              "IPY_MODEL_a10cbc078e6140ddba3eca873eadb2e6",
              "IPY_MODEL_13687442f5924d69bd693b58ab6e18ee"
            ],
            "layout": "IPY_MODEL_8666f2904ef64f2ca1c546242bc915ee"
          }
        },
        "7260aa6f7f694f82a22fed46a50d3e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa3e34fc33344599f17499f2d473aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8666f2904ef64f2ca1c546242bc915ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880afdb881994abb8f0e6b59939251ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10ede8a5a38b4147a99cce538b5bd073",
            "placeholder": "​",
            "style": "IPY_MODEL_08302858a534406bacfc8cb5b859ea8d",
            "value": " 80.0/80.0 [00:00&lt;00:00, 2.73kB/s]"
          }
        },
        "91d314fdc8ec47869345ed35bd73d934": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bb792307c8467ea10279e58c4370b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eaba0aa2c164b25bc4ba5b34cc81bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_990334ee87a24feebd24fc8be8abab03",
            "value": " 473M/473M [00:07&lt;00:00, 67.8MB/s]"
          }
        },
        "959253efbca941baa951d98f4736cd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95abab814a92460d8211684f77f6053d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990334ee87a24feebd24fc8be8abab03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b0d5207329441069ba629eb51ea244a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e090d2a7f0748fbab197830e082024d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a10cbc078e6140ddba3eca873eadb2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74b516a206e4461b7415ee0f73b46ce",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_599a6fa0336b442faaa126801e3908af",
            "value": 344259
          }
        },
        "a272bbf6f72d4fbe9240c8f2ff86d4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b855be27ed049b1bfa2ac1c2f8e986a",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e090d2a7f0748fbab197830e082024d",
            "value": 80
          }
        },
        "a9a620080f73404fbd0c1a81a9f52b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5d3ee5282747d8b9cb8014f133b251",
            "max": 473243441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7260aa6f7f694f82a22fed46a50d3e1f",
            "value": 473243441
          }
        },
        "b2e590ecf5514faa94e2dc930ee52f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17106db60b784ec68dad93e6351a4250",
              "IPY_MODEL_c1c01014ae4840e1bfb4b276ff2d242b",
              "IPY_MODEL_d62cdd6a62de455e8628094436bc3c65"
            ],
            "layout": "IPY_MODEL_7aa3e34fc33344599f17499f2d473aa1"
          }
        },
        "baed98a8dd804bef872e25b95d485c23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c01014ae4840e1bfb4b276ff2d242b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9af042a63546b681209757f409af1c",
            "max": 620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_487e2198b0c5473d8c4d6f311cb9999b",
            "value": 620
          }
        },
        "d62cdd6a62de455e8628094436bc3c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e808b8e9694473a7fe244e56e49821",
            "placeholder": "​",
            "style": "IPY_MODEL_95abab814a92460d8211684f77f6053d",
            "value": " 620/620 [00:00&lt;00:00, 22.4kB/s]"
          }
        },
        "d74b516a206e4461b7415ee0f73b46ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df417905e2ad42a88690d30bb124c7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d1f57516ff4cd58969c010a9998972": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e48e800ce4e346c299e23e76cceb557a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9af042a63546b681209757f409af1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1006c34b82416d8ac8ef674df1d532": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
