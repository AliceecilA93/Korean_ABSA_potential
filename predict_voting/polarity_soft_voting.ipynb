{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Polarity_soft_Voting"],"metadata":{"id":"ksX_2W_XCe-8"}},{"cell_type":"markdown","source":["## 필수코드"],"metadata":{"id":"znOoc_4jbc-_"}},{"cell_type":"code","source":["# colab 환경 시 필수 설치\n","# 필요 시 설치(가상환경의 경우 터미널에 설치)\n","!pip install transformers==4.24.0"],"metadata":{"id":"kLNmYGmKyCB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# colab 환경 시 필수 설치\n","# 필요 시 설치(가상환경의 경우 터미널에 설치)\n","!pip install datasets==2.6.1"],"metadata":{"id":"4LD_vPDUyEUM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모듈 import"],"metadata":{"id":"QuWu6L3sfOqX"}},{"cell_type":"code","source":["import json\n","import os\n","import torch\n","import torch.nn as nn\n","from tqdm import trange\n","from transformers import AutoModel, AutoTokenizer\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AdamW\n","from datasets import load_metric\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","import copy"],"metadata":{"id":"NUaLN4kgNv7J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 전역 변수 설정"],"metadata":{"id":"bhfTlbocbkKQ"}},{"cell_type":"markdown","source":["### entity_pt파일 지정 및 test파일 지정, 속성, 감성분석 등 설정"],"metadata":{"id":"OCOArg9ZCraT"}},{"cell_type":"code","source":["# soft_voting시 사용할 베이스 모델 설정\n","base_model = 'kykim/electra-kor-base'\n","\n","# 개체#속성 쌍 설정(label25)\n","entity_property_pair = [\n","    '제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도', '제품 전체#다양성',\n","    '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도',\n","    '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#가격', '패키지/구성품#다양성',\n","    '브랜드#일반', '브랜드#가격', '브랜드#품질', '브랜드#인지도', '브랜드#디자인'\n","                    ]\n","\n","# 개체#속성 쌍 설정(label23)\n","# entity_property_pair = [\n","#     '제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도',\n","#     '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도',\n","#     '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#가격', '패키지/구성품#다양성',\n","#     '브랜드#일반', '브랜드#가격', '브랜드#품질', '브랜드#인지도',\n","#                     ]\n","\n","# 문장과 개체#속성 쌍의 관계를 True, False 로 표시\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","# 문장과 개체#속성 쌍의 관계로 감성을 positive, negative, neutral 로 표시\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n","\n","# 그래픽 카드 사용 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 불러온 tokenizer 에 special token 을 추가\n","special_tokens_dict = {\n","    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","}"],"metadata":{"id":"BIC6iY-_jjen"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["json 및 jsonl 파일 read, write 함수"],"metadata":{"id":"Nuj7wDE2cYBs"}},{"cell_type":"code","source":["# json 파일 읽어서 list에 저장\n","def jsonload(fname, encoding=\"utf-8\"):\n","    with open(fname, encoding=encoding) as f:\n","        j = json.load(f)\n","    return j\n","\n","# json 개체를 파일이름으로 깔끔하게 저장\n","def jsondump(j, fname):\n","    with open(fname, \"w\", encoding=\"UTF8\") as f:\n","        json.dump(j, f, ensure_ascii=False)\n","\n","# jsonl 파일 읽어서 list에 저장\n","def jsonlload(fname, encoding=\"utf-8\"):\n","    json_list = []\n","    with open(fname, encoding=encoding) as f:\n","        for line in f.readlines():\n","            json_list.append(json.loads(line))\n","    return json_list"],"metadata":{"id":"pYvG2g1YjlxL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 정의"],"metadata":{"id":"mHAEDh8ww6Wy"}},{"cell_type":"markdown","source":["Electra 모델을 기반으로 한 classification 모델 이용"],"metadata":{"id":"HBKQG0lFfupI"}},{"cell_type":"code","source":["# 아래 ELECTRABaseClassifier의 classifier로 사용될 class\n","class SimpleClassifier(nn.Module):\n","\n","    def __init__(self, num_label):\n","        super().__init__()\n","        self.dense = nn.Linear(classifier_hidden_size, classifier_hidden_size)\n","        self.dropout = nn.Dropout(classifier_dropout_prob)\n","        self.output = nn.Linear(classifier_hidden_size, num_label)\n","\n","    def forward(self, features):\n","        x = features[:, 0, :]\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.output(x)\n","        return x\n","\n","# 불러올 base model 기반 classification 설정\n","class ELECTRABaseClassifier(nn.Module):\n","    def __init__(self, num_label, len_tokenizer):\n","        super(ELECTRABaseClassifier, self).__init__()\n","\n","        self.num_label = num_label\n","        self.xlm_roberta = AutoModel.from_pretrained(base_model)\n","        self.xlm_roberta.resize_token_embeddings(len_tokenizer)\n","\n","        self.labels_classifier = SimpleClassifier(self.num_label)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.xlm_roberta(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=None\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.labels_classifier(sequence_output)\n","\n","        loss = None\n","\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_label),\n","                                                labels.view(-1))\n","\n","        return loss, logits"],"metadata":{"id":"JtipLb6e080w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 로드된 모델 값으로 soft_voting"],"metadata":{"id":"OBAB3KxsxAgS"}},{"cell_type":"code","source":["# 인자로 받아온 모델들을 통해 predict 하는 문장 데이터에 label(entity_property, polarity) 해주는 함수\n","#                                                   모델 갯수에 따라서 pc_model1 추가 또는 삭제\n","def predict_from_korean_form3(tokenizer, ce_model1, pc_model1, pc_model2, pc_model3, data):\n","\n","    ce_model1.to(device)\n","    ce_model1.eval()\n","\n","    for sentence in data:\n","        form = sentence['sentence_form']\n","        sentence['annotation'] = []\n","        if type(form) != str:\n","            print(\"form type is arong: \", form)\n","            continue\n","\n","        # 개체#속성 쌍을 순서대로 입력\n","        for pair in entity_property_pair:\n","            \n","            # 문장과 pair를 tokenizer화 \n","            tokenized_data = tokenizer(form, pair, padding='max_length', max_length=256, truncation=True)\n","            \n","            # tonkenizer 된 값으로 entity_property 모델을 통해 True, False 결과값을 출력\n","            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n","            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n","\n","            # 문장에 대한 각 모델별 점수 예측 결과 저장\n","            with torch.no_grad():\n","                _, ce_logits1 = ce_model1(input_ids, attention_mask)\n","\n","            ce_predictions = torch.argmax(ce_logits1, dim = -1)\n","\n","            ce_result = tf_id_to_name[ce_predictions[0]]\n","\n","            # True 일 경우에만 다음 코드 진행\n","            if ce_result == 'True':\n","\n","                # tonkenizer 된 값으로 polarity 모델을 통해 Positive, Negative,Neutral 결과값을 출력                \n","                with torch.no_grad():\n","                    # 모델 갯수에 따라 추가 또는 삭제\n","                    _, pc_logits1 = pc_model1(input_ids, attention_mask)\n","                    _, pc_logits2 = pc_model2(input_ids, attention_mask)\n","                    _, pc_logits3 = pc_model3(input_ids, attention_mask)\n","\n","                # 예측한 결과값에 대한 평균 구하기\n","                        # 모델 갯수에 따라 추가 또는 삭제\n","                logits1 = (pc_logits1[0][0]+pc_logits2[0][0]+pc_logits3[0][0])/3\n","                logits2 = (pc_logits1[0][1]+pc_logits2[0][1]+pc_logits3[0][1])/3\n","                logits3 = (pc_logits1[0][2]+pc_logits2[0][2]+pc_logits3[0][2])/3\n","\n","                pc_logits = torch.tensor([[logits1, logits2, logits3]]).to(device)\n","\n","                pc_predictions = torch.argmax(pc_logits, dim=-1)\n","                pc_result = polarity_id_to_name[pc_predictions[0]]\n","\n","                # entity_property 모델과 polarity 모델을 통해서 출력 된 결과 값을 label 입력\n","                sentence['annotation'].append([pair, pc_result])\n","\n","    return data"],"metadata":{"id":"lUpyAhIV6O4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 지정된 모델들 불러오기"],"metadata":{"id":"aSQUIAptwkbl"}},{"cell_type":"code","source":["# 불러올 entity_property pt 파일 경로 설정\n","entity_classification_model_path = './'\n","\n","# 불러올 polarity pt 파일 경로 설정\n","# 3개인 경우 예시\n","polarity_classification_model_path1 = './'\n","polarity_classification_model_path2 = './'\n","polarity_classification_model_path3 = './'\n","\n","# 학습 후 저장된 pt 파일로 predict 할 json 데이터 설정\n","test_data_path = './'"],"metadata":{"id":"M3eOCCwNCCEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 변수로 지정된 경로에 따라 predict 파일에 labeling 후 저장하는 함수\n","def test_sentiment_analysis():\n","\n","    # predict 시 사용할 tokenizer와 데이터를 불러오기\n","    tokenizer = AutoTokenizer.from_pretrained(base_model)\n","    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","    test_data = jsonlload(test_data_path)\n","    \n","    # entity_property 모델 불러오기\n","    model1 = RoBertaBaseClassifier(len(tf_id_to_name), len(tokenizer))\n","    model1.load_state_dict(torch.load(entity_classification_model_path, map_location=device))\n","    model1.to(device)\n","    model1.eval()\n","    \n","    # polarity 모델 불러오기 \n","    # 모델 갯수에 따라 polarity_model1 추가 또는 삭제\n","    polarity_model1 = RoBertaBaseClassifier(len(polarity_id_to_name), len(tokenizer))\n","    polarity_model1.load_state_dict(torch.load(polarity_classification_model_path1, map_location=device))\n","    polarity_model1.to(device)\n","    polarity_model1.eval()\n","\n","    # 모델 갯수에 따라 polarity_model2 추가 또는 삭제\n","    polarity_model2 = RoBertaBaseClassifier(len(polarity_id_to_name), len(tokenizer))\n","    polarity_model2.load_state_dict(torch.load(polarity_classification_model_path2, map_location=device))\n","    polarity_model2.to(device)\n","    polarity_model2.eval()\n","\n","    # 모델 갯수에 따라 polarity_model3 추가 또는 삭제\n","    polarity_model3 = RoBertaBaseClassifier(len(polarity_id_to_name), len(tokenizer))\n","    polarity_model3.load_state_dict(torch.load(polarity_classification_model_path3, map_location=device))\n","    polarity_model3.to(device)\n","    polarity_model3.eval()\n","\n","    # predict_from_korean_form 함수를 통해 predict 데이터 만들기\n","    # 모델 갯수에 따라 polarity_model 추가 또는 삭제\n","    pred_data = predict_from_korean_form3(tokenizer, model1, polarity_model1,  polarity_model2, polarity_model3, copy.deepcopy(test_data))\n","            \n","    jsondump(pred_data, './')"],"metadata":{"id":"rd4wXtpOFZ5l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##실행코드"],"metadata":{"id":"1aQPuVMfxd7R"}},{"cell_type":"code","source":["# 변수로 지정된 경로에 따라 predict 파일을 생성 및 저장 함수\n","test_sentiment_analysis()"],"metadata":{"id":"hODIoSLjFb_s"},"execution_count":null,"outputs":[]}]}